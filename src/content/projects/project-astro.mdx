# Project ASTRO

A local-first, OS-level assistant built to feel like a real on-device operator: always available, deeply integrated, and packaged so it installs and runs like actual software—not a weekend demo.

## Core principles
- **Local-first execution**: keeps working with zero internet
- **Network-aware**: uses online tools when available, never depends on them
- **OS-level control plane**: natural language → safe, verified system actions

## Intelligence stack
- **Meta Llama models (offline)** for reasoning and command understanding
- **Command training** around how humans actually speak (“turn the lights down”)
- **Self-learning**: improves over time by learning preferences, routines, and corrections

## What it controls (target)
- OS + devices: volume, apps, files, media, workflows
- Smart home: lights, scenes, devices, automations
- Beyond basics: multi-step tasks that combine tools (not just reminders + email)

## Voice
- **Hume AI** integration for a natural, expressive voice interface

## Packaging goal
- Installable, runnable, and maintainable (setup + updates + sane defaults)

## Roadmap
### V1 — Useful on day one
- Local command execution for common actions (volume, media, app launching)
- Smart home control (lights/scenes/devices)
- Basic tool actions (file search + simple file ops)
- Stable configuration + clean install/run flow

### V2 — Workflows, not commands
- Multi-step tasks (e.g., “prep me for tomorrow” across calendar + notes + files)
- Safer action confirmation and audit trail
- Better personalization (preferences, routines, context memory)

### V3 — Adaptive and proactive
- Self-learning from corrections and patterns (with guardrails)
- More autonomous orchestration across devices/services
- Expanded voice experience and richer interaction modes

